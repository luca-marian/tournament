{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULCRUM - TOURNAMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "# luca\n",
    "path_luca_json = \"./data/map_business_to_naics.json\"\n",
    "path_luca_json2 = \"./data/map_company_naics.json\"\n",
    "path_luca_json_lower = \"./data/map_company_naics_lower.json\"\n",
    "\n",
    "# alex\n",
    "dataset_path = './data/cleaned_dataset.csv'\n",
    "\n",
    "embeddings_commercial_name_path = './data/embeddings_commercial_name_all.npy'\n",
    "embeddings_short_description_path = './data/embeddings_short_description.npy'\n",
    "embeddings_description_path = './data/embeddings_description_all.npy'\n",
    "\n",
    "# vali \n",
    "NAICS_KEYWORDS_PATH = './data/naics_summary_keywords.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "loaded_embeddings_commercial_name = np.load(embeddings_commercial_name_path)\n",
    "loaded_embeddings_short_description = np.load(embeddings_short_description_path)\n",
    "loaded_embeddings_description = np.load(embeddings_description_path)\n",
    "\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "#! Commercial name - cred\n",
    "\n",
    "def round_1(company_name):\n",
    "    sen = [company_name]\n",
    "    sen_embeddings = model.encode(sen)\n",
    "\n",
    "    results = cosine_similarity(\n",
    "        [sen_embeddings[0]],\n",
    "        loaded_embeddings_commercial_name[0:]\n",
    "    )\n",
    "    sim_value = results.max() # value\n",
    "    label = data.iloc[results.argmax()]['naics_label'] # label\n",
    "    return label\n",
    "\n",
    "#! Short description\n",
    "\n",
    "def round_3(short_description):\n",
    "    sen = [short_description]\n",
    "    sen_embeddings = model.encode(sen)\n",
    "\n",
    "    results = cosine_similarity(\n",
    "        [sen_embeddings[0]],\n",
    "        loaded_embeddings_short_description[0:]\n",
    "    )\n",
    "    sim_value = results.max()\n",
    "    label = data.iloc[results.argmax()]['naics_label']\n",
    "    return label\n",
    "\n",
    "#! Description\n",
    "\n",
    "def round_4(description):\n",
    "    sen = [description]\n",
    "    sen_embeddings = model.encode(sen)\n",
    "\n",
    "    results = cosine_similarity(\n",
    "        [sen_embeddings[0]],\n",
    "        loaded_embeddings_description[0:]\n",
    "    )\n",
    "    sim_value = results.max()\n",
    "    label = data.iloc[results.argmax()]['naics_label']\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Vali - keywords for Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>naics_code</th>\n",
       "      <th>naics_label</th>\n",
       "      <th>description</th>\n",
       "      <th>summary</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>Crop Production</td>\n",
       "      <td>Industries in the Crop Production subsector gr...</td>\n",
       "      <td>The Crop Production subsector comprises establ...</td>\n",
       "      <td>Crop Production, farms, orchards, greenhouses,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>Animal Production and Aquaculture</td>\n",
       "      <td>Industries in the Animal Production and Aquacu...</td>\n",
       "      <td>The Animal Production and Aquaculture subsecto...</td>\n",
       "      <td>Animal Production, Aquaculture, Ranches, Farms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>Forestry and Logging</td>\n",
       "      <td>Industries in the Forestry and Logging subsect...</td>\n",
       "      <td>The forestry and logging industries harvest ti...</td>\n",
       "      <td>Forestry, Logging, Timber Production, Reforest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "      <td>Fishing, Hunting and Trapping</td>\n",
       "      <td>Industries in the Fishing, Hunting and Trappin...</td>\n",
       "      <td>The Fishing, Hunting and Trapping industry rel...</td>\n",
       "      <td>Fishing, Hunting, Trapping, Harvest, Wild Anim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>Support Activities for Agriculture and Forestry</td>\n",
       "      <td>Industries in the Support Activities for Agric...</td>\n",
       "      <td>The Support Activities for Agriculture and For...</td>\n",
       "      <td>Support Activities, Agriculture, Forestry, Sup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  naics_code                                      naics_label  \\\n",
       "0           0         111                                  Crop Production   \n",
       "1           1         112                Animal Production and Aquaculture   \n",
       "2           2         113                             Forestry and Logging   \n",
       "3           3         114                    Fishing, Hunting and Trapping   \n",
       "4           4         115  Support Activities for Agriculture and Forestry   \n",
       "\n",
       "                                         description  \\\n",
       "0  Industries in the Crop Production subsector gr...   \n",
       "1  Industries in the Animal Production and Aquacu...   \n",
       "2  Industries in the Forestry and Logging subsect...   \n",
       "3  Industries in the Fishing, Hunting and Trappin...   \n",
       "4  Industries in the Support Activities for Agric...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The Crop Production subsector comprises establ...   \n",
       "1  The Animal Production and Aquaculture subsecto...   \n",
       "2  The forestry and logging industries harvest ti...   \n",
       "3  The Fishing, Hunting and Trapping industry rel...   \n",
       "4  The Support Activities for Agriculture and For...   \n",
       "\n",
       "                                            keywords  \n",
       "0  Crop Production, farms, orchards, greenhouses,...  \n",
       "1  Animal Production, Aquaculture, Ranches, Farms...  \n",
       "2  Forestry, Logging, Timber Production, Reforest...  \n",
       "3  Fishing, Hunting, Trapping, Harvest, Wild Anim...  \n",
       "4  Support Activities, Agriculture, Forestry, Sup...  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_naics_keyw = pd.read_csv(NAICS_KEYWORDS_PATH)\n",
    "pd_naics_keyw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def remove_mentions_and_hashtags(text):\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "    # Remove punctuation using the translation table\n",
    "    text_without_punct = text.translate(translator)\n",
    "\n",
    "    return text_without_punct\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_sentence = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_stop == False:\n",
    "            filtered_sentence.append(token.text)\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "\n",
    "def clean_text(text,to_lemmatize:bool = True):\n",
    "\n",
    "    # Standardize text\n",
    "    # text = standardize_accented_chars(text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Remove mentions and hashtags\n",
    "    text = remove_mentions_and_hashtags(text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = remove_numbers(text)\n",
    "\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r\"\\W\", \" \", text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    text = remove_stopwords(text)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text, flags=re.I)\n",
    "\n",
    "    if to_lemmatize:\n",
    "        text = lemmatize(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    text = \" \".join([token.lemma_ for token in doc])\n",
    "    return text\n",
    "\n",
    "# Calculate similarity\n",
    "def calculate_similarity(keywords, tokens):\n",
    "    \n",
    "    text1 = nlp(\" \".join(keywords))\n",
    "    text2 = nlp(\" \".join(tokens))\n",
    "    \n",
    "    return text1.similarity(text2)\n",
    "\n",
    "\n",
    "def predict_industry_label(keywords, industry_data):\n",
    "    label_key = 'naics_label'\n",
    "    code_key = 'naics_code'\n",
    "\n",
    "#Precompute similarities if possible\n",
    "    similarities = industry_data['tokens'].apply(lambda tokens: calculate_similarity(keywords, tokens))\n",
    "\n",
    "    # Find index of the maximum similarity\n",
    "    max_index = similarities.idxmax()\n",
    "    max_similarity = similarities[max_index]\n",
    "    \n",
    "    # predicted_label = industry_data.at[max_index, code_key]\n",
    "    # predicted_label = str(predicted_label) + \" \" + str(industry_data.at[max_index, label_key])\n",
    "    predicted_code = str(industry_data.at[max_index, code_key])\n",
    "    predicted_label = str(industry_data.at[max_index, label_key])\n",
    "\n",
    "    return predicted_label, predicted_code, max_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textile product mills nonapparel textile product sheet towel cut sew textile industry textile product purchase fabric cutting sewing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "industry_data = pd_naics_keyw\n",
    "\n",
    "# Preprocess industry descriptions\n",
    "industry_data['processed_description'] = industry_data['keywords'].str.lower()\n",
    "industry_data['processed_description'] = [clean_text(text) for text in industry_data['processed_description']]\n",
    "\n",
    "\n",
    "print(industry_data['processed_description'][15])\n",
    "\n",
    "# apply clean_text function to the column 'processed_description'\n",
    "industry_data['processed_description'] = industry_data['processed_description'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Tokenize and embed industry descriptions\n",
    "industry_data['tokens'] = industry_data['processed_description'].apply(lambda x: [token.text for token in nlp(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\n",
    "    path_luca_json\n",
    ")\n",
    "label_dict_l = json.load(f)\n",
    "\n",
    "def map_bussines_to_naics(taxonomy:str):\n",
    "    return label_dict_l.get(taxonomy, \"abstain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def read_map(path_json: str):\n",
    "    f = open(path_json)\n",
    "    map_company_comercial = json.load(f)\n",
    "    return map_company_comercial\n",
    "\n",
    "map_company_naics = read_map(path_luca_json_lower)\n",
    "\n",
    "def fuzzy_match_naics_round1(company_name, threshold: int = 50):\n",
    "    matches = process.extractOne(\n",
    "        company_name, map_company_naics.keys(), scorer=fuzz.WRatio\n",
    "    )\n",
    "\n",
    "    return map_company_naics[matches[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = 'http://116.202.111.229:8000'\n",
    "# api_key = 'VPLrVk4hSZMdGrW2wAP0GTpsV2Jsdx5Z'\n",
    "\n",
    "# headers = {\n",
    "#     'x-api-key': api_key\n",
    "# }\n",
    "\n",
    "# rounds = 5\n",
    "# current_round = 1\n",
    "\n",
    "# filename = 'extra_data.csv'\n",
    "# data_columns = ['commercial_name', 'business_tags', 'short_descripti', 'description', 'main_business_category', 'naics']\n",
    "\n",
    "# index = 0\n",
    "\n",
    "# count_abstain = 0\n",
    "# guesses = [\"\", \"\", \"\", \"\", \"\"]\n",
    "\n",
    "# # Get a new hint for current company or get the first hint for a new company after calling /evaluate/reset\n",
    "#     response = requests.get(f\"{base_url}/evaluate/hint\", headers=headers)\n",
    "\n",
    "#     print(response.status_code, response.json())\n",
    "    \n",
    "#     # Get the hint\n",
    "#     hint = response.json()['hint']\n",
    "\n",
    "#     # predict based off given hint\n",
    "#     time.sleep(1)\n",
    "    \n",
    "#     [final_answer, final_code, final_similarity] = [\"abstain\", \"?\", \"?\"]\n",
    "    \n",
    "#     if current_round == 1:\n",
    "#         # final_answer = round_1(hint)\n",
    "#         final_answer = fuzzy_match_naics_round1(hint)\n",
    "#     elif current_round == 2:\n",
    "#         input_keywords = hint.split(\"|\")\n",
    "    \n",
    "#         print(\"Keywords: \", input_keywords)\n",
    "#         [final_answer, final_code, final_similarity] = predict_industry_label(input_keywords, industry_data)\n",
    "#     # elif current_round == 3:\n",
    "#     #     final_answer = round_3(hint)\n",
    "#     elif current_round == 3:\n",
    "#         # get the first 5 keywords from the text using spacy\n",
    "#         doc = nlp(hint)\n",
    "#         input_keywords = [chunk.text for chunk in doc.noun_chunks][:3]\n",
    "#         [final_answer, final_code, final_similarity] = predict_industry_label(input_keywords, industry_data)\n",
    "#     elif current_round == 4:\n",
    "#         # final_answer = round_4(hint)\n",
    "#         final_answer = \"abstain\"\n",
    "#     else:\n",
    "#         final_answer = map_bussines_to_naics(hint)\n",
    "        \n",
    "#     guesses[current_round - 1] = final_answer\n",
    "    \n",
    "#     # if count_abstain == 0 and current_round >= 3 and guesses[current_round - 2] != final_answer:\n",
    "#     #     count_abstain = count_abstain + 1\n",
    "#     #     final_answer = \"abstain\"\n",
    "\n",
    "#     # Post your answer for current hint\n",
    "#     data_send = {\n",
    "#         'answer': final_answer\n",
    "#     }\n",
    "    \n",
    "#     print(\"Guess: \", final_answer)\n",
    "#     if current_round == 2:\n",
    "#         print(\"Code: \", final_code)\n",
    "#         print(\"Similarity: \", final_similarity)\n",
    "    \n",
    "#     response = requests.post(f\"{base_url}/evaluate/answer\", json=data_send, headers=headers)\n",
    "\n",
    "#     print(response.status_code, response.json())\n",
    "    \n",
    "#     print(\"\")\n",
    "    \n",
    "#     current_round = current_round + 1\n",
    "#     time.sleep(1)\n",
    "\n",
    "# # Get hints about a new company\n",
    "# current_round = 1\n",
    "# index = index + 1\n",
    "\n",
    "# response = requests.get(f\"{base_url}/evaluate/reset\", headers=headers)\n",
    "\n",
    "# print(response.status_code, response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional, Scientific, and Technical Services\n",
      "Hospitals\n"
     ]
    }
   ],
   "source": [
    "testtesttest = fuzzy_match_naics_round1(\"Hospitals & others\")\n",
    "print(testtesttest)\n",
    "input_keywordszzz = [\"Hospitals\", \"medic\"]\n",
    "[test2, _, __] = predict_industry_label(input_keywordszzz, industry_data)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://116.202.111.229:8000'\n",
    "api_key = 'VPLrVk4hSZMdGrW2wAP0GTpsV2Jsdx5Z'\n",
    "\n",
    "headers = {\n",
    "    'x-api-key': api_key\n",
    "}\n",
    "\n",
    "rounds = 5\n",
    "current_round = 1\n",
    "\n",
    "filename = 'extra_data.csv'\n",
    "data_columns = ['commercial_name', 'business_tags', 'short_descripti', 'description', 'main_business_category', 'naics']\n",
    "\n",
    "index = 0\n",
    "\n",
    "count_abstain = 0\n",
    "guesses = [\"\", \"\", \"\", \"\", \"\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {'company_id': 38, 'level': 5, 'hint': 'Bakeries & Desserts'}\n",
      "200 {'response': 'ack'}\n",
      "Guess:  Food and Beverage Retailers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get a new hint for current company or get the first hint for a new company after calling /evaluate/reset\n",
    "response = requests.get(f\"{base_url}/evaluate/hint\", headers=headers)\n",
    "\n",
    "print(response.status_code, response.json())\n",
    "\n",
    "# Get the hint\n",
    "hint = response.json()['hint']\n",
    "\n",
    "# predict based off given hint\n",
    "time.sleep(1)\n",
    "\n",
    "[final_answer, final_code, final_similarity] = [\"abstain\", \"?\", \"?\"]\n",
    "\n",
    "if current_round == 1:\n",
    "    # final_answer = round_1(hint)\n",
    "    # final_answer = fuzzy_match_naics_round1(hint)\n",
    "    final_answer = fuzzy_match_naics_round1(hint.lower())\n",
    "elif current_round == 2:\n",
    "    input_keywords = hint.split(\"|\")\n",
    "\n",
    "    print(\"Keywords: \", input_keywords)\n",
    "    [final_answer, final_code, final_similarity] = predict_industry_label(input_keywords, industry_data)\n",
    "# elif current_round == 3:\n",
    "#     final_answer = round_3(hint)\n",
    "elif current_round == 3:\n",
    "    # get the first 5 keywords from the text using spacy\n",
    "    doc = nlp(hint)\n",
    "    input_keywords = [chunk.text for chunk in doc.noun_chunks][:3]\n",
    "    [final_answer, final_code, final_similarity] = predict_industry_label(input_keywords, industry_data)\n",
    "elif current_round == 4:\n",
    "    # final_answer = round_4(hint)\n",
    "    final_answer = \"abstain\"\n",
    "else:\n",
    "    final_answer = map_bussines_to_naics(hint)\n",
    "    \n",
    "guesses[current_round - 1] = final_answer\n",
    "\n",
    "# Post your answer for current hint\n",
    "data_send = {\n",
    "    'answer': final_answer\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{base_url}/evaluate/answer\", json=data_send, headers=headers)\n",
    "\n",
    "print(response.status_code, response.json())\n",
    "\n",
    "print(\"Guess: \", final_answer)\n",
    "if current_round == 2:\n",
    "    print(\"Code: \", final_code)\n",
    "    print(\"Similarity: \", final_similarity)\n",
    "\n",
    "current_round = current_round + 1\n",
    "if current_round > 5:\n",
    "    current_round = 1\n",
    "# time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {'response': 'Wait for 226.31919360160828 seconds'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = requests.get(f\"{base_url}/evaluate/reset\", headers=headers)\n",
    "\n",
    "print(response.status_code, response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
