{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you run on colab\n",
    "%pip install transformers\n",
    "%pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BertModel\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def remove_mentions_and_hashtags(text):\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "    # Remove punctuation using the translation table\n",
    "    text_without_punct = text.translate(translator)\n",
    "\n",
    "    return text_without_punct\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_sentence = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_stop == False:\n",
    "            filtered_sentence.append(token.text)\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # Standardize text\n",
    "    # text = standardize_accented_chars(text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Remove mentions and hashtags\n",
    "    text = remove_mentions_and_hashtags(text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = remove_numbers(text)\n",
    "\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r\"\\W\", \" \", text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    text = remove_stopwords(text)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text, flags=re.I)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    text = \" \".join([token.lemma_ for token in doc])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_pred, y_test, title: str = \"Confusion Matrix\"):\n",
    "    from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred,average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred,average='weighted')}\")\n",
    "    print(f\"F1: {f1_score(y_test, y_pred,average='weighted')}\")\n",
    "    print(f\"Metthew corr: {matthews_corrcoef(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # sns.heatmap(cm, annot=True, fmt=\"g\")\n",
    "    # plt.title(title)\n",
    "    # plt.xlabel(\"Predicted\")\n",
    "    # plt.ylabel(\"True\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    \"\"\"Function to split dataset into train, val and test\"\"\"\n",
    "    np.random.seed(112)\n",
    "    df_train, df_val, df_test = np.split(\n",
    "        data.sample(frac=1, random_state=42),\n",
    "        [int(0.8 * len(data)), int(0.9 * len(data))],\n",
    "    )\n",
    "\n",
    "    # Print dimensions\n",
    "    print(len(df_train), len(df_val), len(df_test))\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "DATA_PATH = os.path.join(parent_directory, \"data\")\n",
    "DATA_TOURNAMENT = os.path.join(DATA_PATH, \"tournament_hints_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/marianluca/Projects/HackingBigNumbers/Tournament/marian\n",
      "Parent Directory: /Users/marianluca/Projects/HackingBigNumbers/Tournament\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "DATA_PATH = os.path.join(parent_directory,\"data\")\n",
    "DATA_TOURNAMENT = os.path.join(DATA_PATH,\"tournament_hints_data.parquet\")\n",
    "\n",
    "print(\"Current Directory:\", current_directory)\n",
    "print(\"Parent Directory:\", parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commercial_name</th>\n",
       "      <th>business_tags</th>\n",
       "      <th>short_description</th>\n",
       "      <th>description</th>\n",
       "      <th>main_business_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>White Horse</td>\n",
       "      <td>Tile Manufacturing | European Aesthetics Ceram...</td>\n",
       "      <td>White Horse is highly regarded as a tile trail...</td>\n",
       "      <td>White Horse Ceramic Singapore is a leading man...</td>\n",
       "      <td>Tile Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wealth Solution Partners</td>\n",
       "      <td>Super and SMSF Services | Financial Planning a...</td>\n",
       "      <td>WSP, Wealth Solution Partners, Financial Plann...</td>\n",
       "      <td>Wealth Solution Partners Pty Ltd is an indepen...</td>\n",
       "      <td>Investment Consultants &amp; Financial Advisors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMG</td>\n",
       "      <td>Fire and Water Cleanup Services | Mold Remedia...</td>\n",
       "      <td>PMG General Solutions Inc. is an environmental...</td>\n",
       "      <td>PMG General Solutions Inc. is an environmental...</td>\n",
       "      <td>Damage Restoration &amp; Mold Remediation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TMP Capital PLLC</td>\n",
       "      <td>Licensed in AL &amp; FL | 203K Loans | 15-year Fix...</td>\n",
       "      <td>TMP Capital PLLC Consulting Company Franklin M...</td>\n",
       "      <td>TMP Capital PLLC Consulting Company, also know...</td>\n",
       "      <td>Mortgage Brokers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genertek Power</td>\n",
       "      <td>Industrial and Commercial Energy Storage | Ass...</td>\n",
       "      <td>Genertek Power Ltd a UK electricity systems &amp; ...</td>\n",
       "      <td>Genertek Power Limited is a privately-owned UK...</td>\n",
       "      <td>Renewable energy companies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626241</th>\n",
       "      <td>Global Golf Tech Solutions</td>\n",
       "      <td>Manufacturing | Golf Academy | G Launch Monito...</td>\n",
       "      <td>The best personal golf launch monitor screen p...</td>\n",
       "      <td>Global Golf Tech Solutions is a company that s...</td>\n",
       "      <td>Golf Courses &amp; Country Clubs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626242</th>\n",
       "      <td>Renko</td>\n",
       "      <td>Latest Processing Technologies | E Gaskets for...</td>\n",
       "      <td>EPDM Rubber products from Renko can be found o...</td>\n",
       "      <td>RENKO is a company that has been producing hig...</td>\n",
       "      <td>Fabricated Rubber Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626243</th>\n",
       "      <td>Norstal</td>\n",
       "      <td>Residential Buildings | Custom Project Service...</td>\n",
       "      <td>Norstal produces a broad range of steel struct...</td>\n",
       "      <td>Norstal is a steel structure producer that spe...</td>\n",
       "      <td>Metal Fabrication Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626244</th>\n",
       "      <td>Acoustic</td>\n",
       "      <td>Wood-based Acoustic Products Manufacturer | De...</td>\n",
       "      <td>We are designed and manufactured in UAE, Acous...</td>\n",
       "      <td>Acoustic.ae is a member of a UAE-based group o...</td>\n",
       "      <td>Building Material Manufacturers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626245</th>\n",
       "      <td>PAPER MACHINE CLOTHING</td>\n",
       "      <td>Detailed Machine Studies and Analytics | Scree...</td>\n",
       "      <td>With Huatao innovative product portfolio of pa...</td>\n",
       "      <td>Huatao Group, also known as Huatao Group, is a...</td>\n",
       "      <td>Paper &amp; Cardboard Products</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626246 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   commercial_name  \\\n",
       "0                      White Horse   \n",
       "1         Wealth Solution Partners   \n",
       "2                              PMG   \n",
       "3                 TMP Capital PLLC   \n",
       "4                   Genertek Power   \n",
       "...                            ...   \n",
       "626241  Global Golf Tech Solutions   \n",
       "626242                       Renko   \n",
       "626243                     Norstal   \n",
       "626244                    Acoustic   \n",
       "626245      PAPER MACHINE CLOTHING   \n",
       "\n",
       "                                            business_tags  \\\n",
       "0       Tile Manufacturing | European Aesthetics Ceram...   \n",
       "1       Super and SMSF Services | Financial Planning a...   \n",
       "2       Fire and Water Cleanup Services | Mold Remedia...   \n",
       "3       Licensed in AL & FL | 203K Loans | 15-year Fix...   \n",
       "4       Industrial and Commercial Energy Storage | Ass...   \n",
       "...                                                   ...   \n",
       "626241  Manufacturing | Golf Academy | G Launch Monito...   \n",
       "626242  Latest Processing Technologies | E Gaskets for...   \n",
       "626243  Residential Buildings | Custom Project Service...   \n",
       "626244  Wood-based Acoustic Products Manufacturer | De...   \n",
       "626245  Detailed Machine Studies and Analytics | Scree...   \n",
       "\n",
       "                                        short_description  \\\n",
       "0       White Horse is highly regarded as a tile trail...   \n",
       "1       WSP, Wealth Solution Partners, Financial Plann...   \n",
       "2       PMG General Solutions Inc. is an environmental...   \n",
       "3       TMP Capital PLLC Consulting Company Franklin M...   \n",
       "4       Genertek Power Ltd a UK electricity systems & ...   \n",
       "...                                                   ...   \n",
       "626241  The best personal golf launch monitor screen p...   \n",
       "626242  EPDM Rubber products from Renko can be found o...   \n",
       "626243  Norstal produces a broad range of steel struct...   \n",
       "626244  We are designed and manufactured in UAE, Acous...   \n",
       "626245  With Huatao innovative product portfolio of pa...   \n",
       "\n",
       "                                              description  \\\n",
       "0       White Horse Ceramic Singapore is a leading man...   \n",
       "1       Wealth Solution Partners Pty Ltd is an indepen...   \n",
       "2       PMG General Solutions Inc. is an environmental...   \n",
       "3       TMP Capital PLLC Consulting Company, also know...   \n",
       "4       Genertek Power Limited is a privately-owned UK...   \n",
       "...                                                   ...   \n",
       "626241  Global Golf Tech Solutions is a company that s...   \n",
       "626242  RENKO is a company that has been producing hig...   \n",
       "626243  Norstal is a steel structure producer that spe...   \n",
       "626244  Acoustic.ae is a member of a UAE-based group o...   \n",
       "626245  Huatao Group, also known as Huatao Group, is a...   \n",
       "\n",
       "                             main_business_category  \n",
       "0                                        Tile Store  \n",
       "1       Investment Consultants & Financial Advisors  \n",
       "2             Damage Restoration & Mold Remediation  \n",
       "3                                  Mortgage Brokers  \n",
       "4                        Renewable energy companies  \n",
       "...                                             ...  \n",
       "626241                 Golf Courses & Country Clubs  \n",
       "626242                   Fabricated Rubber Products  \n",
       "626243                   Metal Fabrication Services  \n",
       "626244              Building Material Manufacturers  \n",
       "626245                   Paper & Cardboard Products  \n",
       "\n",
       "[626246 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_TOURNAMENT)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'commercial_name', 'description', 'short_description', 'business_tags'}\n"
     ]
    }
   ],
   "source": [
    "columns_round = set(df.columns)\n",
    "columns_round.remove(\"main_business_category\")\n",
    "print(columns_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Creating an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fitting the encoder\n",
    "encoder.fit(df[\"main_business_category\"].unique())\n",
    "\n",
    "# Transforming the data\n",
    "df[\"target\"] = encoder.transform(df[\"main_business_category\"])\n",
    "# print(\"Encoded data:\", encoded_data)\n",
    "\n",
    "# Inverse transforming the data\n",
    "# decoded_data = encoder.inverse_transform(encoded_data)\n",
    "# print(\"Decoded data:\", decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500996 62625 62625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianluca/anaconda3/envs/env_pytorch/lib/python3.9/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = split_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bow(X_train, X_test):\n",
    "    # count_vect = CountVectorizer()\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    tfidf_transformer = TfidfVectorizer()\n",
    "\n",
    "    # X_train = count_vect.fit_transform(X_train)\n",
    "    X_train = tfidf_transformer.fit_transform(X_train)\n",
    "\n",
    "    # X_test = count_vect.transform(X_test)\n",
    "    X_test = tfidf_transformer.transform(X_test)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def apply_traditional_algorithms(df_train, df_test, pipeline_cls, threshold=0.5):\n",
    "\n",
    "    X_train, y_train = df_train[\"clean_text\"], df_train[\"target\"]\n",
    "    X_test, y_test = df_test[\"clean_text\"], df_test[\"target\"]\n",
    "\n",
    "    X_train, X_test = apply_bow(X_train, X_test)\n",
    "\n",
    "    best_model, best_model_name = None, None\n",
    "    base_f1_score = 0\n",
    "    for Name, cls in pipeline_cls.items():\n",
    "        cls.fit(X_train, y_train)\n",
    "        y_proba = cls.predict_proba(X_test)\n",
    "        y_pred = (y_proba[:, 1] >= threshold).astype(int)\n",
    "\n",
    "        print(Name)\n",
    "        print(cls)\n",
    "        print(\"Metrics for \" + str(Name) + \"\\n\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        print_metrics(y_pred, y_test, Name + \" - Text\")\n",
    "\n",
    "        if f1_score(y_test, y_pred, average=\"macro\") > base_f1_score:\n",
    "            base_f1_score = f1_score(y_test, y_pred, average=\"macro\")\n",
    "            best_model = cls\n",
    "            best_model_name = Name\n",
    "\n",
    "        print(f\"Test set F1-score: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "        print(f\"Test set Precision {precision_score(y_test,y_pred,average='macro')}\")\n",
    "        print(f\"Test set Recall {recall_score(y_test, y_pred,average='macro')}\")\n",
    "        print(\"\\n\\n\")\n",
    "        print(\n",
    "            \"-----------------------------------------------------------------------------------------------------------------------\"\n",
    "        )\n",
    "\n",
    "    return best_model, best_model_name, base_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_classifiers = {\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(class_weight=\"balanced\"),\n",
    "    \"XGBClassifier\": XGBClassifier(scale_pos_weight=1, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"SVC\": SVC(class_weight=\"balanced\", probability=True),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/3h9bj6ps6t965wjwwkvd77nh0000gn/T/ipykernel_13500/1559582896.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tmp_train.rename(columns={col_name: \"clean_text\"}, inplace=True)\n",
      "/var/folders/kc/3h9bj6ps6t965wjwwkvd77nh0000gn/T/ipykernel_13500/1559582896.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tmp_test.rename(columns={col_name:\"clean_text\"},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for col_name in columns_round:\n",
    "    df_tmp_train, df_tmp_test = (\n",
    "        df_val[[col_name, \"target\"]],\n",
    "        df_test[[col_name, \"target\"]],\n",
    "    )\n",
    "\n",
    "    df_tmp_train.rename(columns={col_name: \"clean_text\"}, inplace=True)\n",
    "    df_tmp_test.rename(columns={col_name:\"clean_text\"},inplace=True)\n",
    "\n",
    "    apply_traditional_algorithms(df_tmp_train, df_tmp_test, pipeline_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "class BERTClass(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bert_model: str = \"bert-base-uncased\",\n",
    "        num_classes: int = 2,\n",
    "        droput_rate: int = 0.3,\n",
    "    ):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model, return_dict=True)\n",
    "        self.dropout = nn.Dropout(droput_rate)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
