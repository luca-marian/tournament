{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run if you run on colab\n",
    "# %pip install transformers\n",
    "# %pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BertModel\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def remove_mentions_and_hashtags(text):\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "    # Remove punctuation using the translation table\n",
    "    text_without_punct = text.translate(translator)\n",
    "\n",
    "    return text_without_punct\n",
    "\n",
    "\n",
    "def remove_stopwords(text, to_lemmatize:bool = False):\n",
    "    filtered_sentence = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_stop == False:\n",
    "            if to_lemmatize:\n",
    "                filtered_sentence.append(token.lemma_)\n",
    "            else:\n",
    "                filtered_sentence.append(token.text)\n",
    "\n",
    "    return \" \".join(filtered_sentence)\n",
    "\n",
    "\n",
    "def clean_text(text,to_lemmatize:bool = True):\n",
    "\n",
    "    # Standardize text\n",
    "    # text = standardize_accented_chars(text)\n",
    "\n",
    "    # Remove URLs\n",
    "    # text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Remove mentions and hashtags\n",
    "    # text = remove_mentions_and_hashtags(text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "\n",
    "    # Remove numbers\n",
    "    # text = remove_numbers(text)\n",
    "\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r\"\\W\", \" \", text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    text = remove_stopwords(text,to_lemmatize)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text, flags=re.I)\n",
    "\n",
    "    # if to_lemmatize:\n",
    "    #     text = lemmatize(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    text = \" \".join([token.lemma_ for token in doc])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_pred, y_test, title: str = \"Confusion Matrix\"):\n",
    "    from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "    print(f\"Reports for {title}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred,average='weighted')}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred,average='weighted')}\")\n",
    "    print(f\"F1: {f1_score(y_test, y_pred,average='weighted')}\")\n",
    "    print(f\"Metthew corr: {matthews_corrcoef(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # cm = confusion_matrix(y_test, y_pred)\n",
    "    # sns.heatmap(cm, annot=True, fmt=\"g\")\n",
    "    # plt.title(title)\n",
    "    # plt.xlabel(\"Predicted\")\n",
    "    # plt.ylabel(\"True\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    \"\"\"Function to split dataset into train, val and test\"\"\"\n",
    "    # np.random.seed(112)\n",
    "    # df_train, df_val, df_test = np.split(\n",
    "    #     data.sample(frac=1, random_state=42),\n",
    "    #     [int(0.8 * len(data)), int(0.9 * len(data))],\n",
    "    # )\n",
    "\n",
    "    # # Print dimensions\n",
    "    # print(len(df_train), len(df_val), len(df_test))\n",
    "\n",
    "    # Split data into train (80%) and temp_test (20%)\n",
    "    df_train, temp_test = train_test_split(\n",
    "        data, test_size=0.05, random_state=42, stratify=data[\"target\"]\n",
    "    )\n",
    "\n",
    "    # Split temp_test into validation (50% of temp_test, 10% of total) and test (50% of temp_test, 10% of total)\n",
    "    df_val, df_test = train_test_split(\n",
    "        temp_test, test_size=0.4, random_state=42, stratify=temp_test[\"target\"]\n",
    "    )\n",
    "\n",
    "    # Print dimensions to verify\n",
    "    print(\n",
    "        f\"Train size: {len(df_train)}, Validation size: {len(df_val)}, Test size: {len(df_test)}\"\n",
    "    )\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_label = pd.read_csv(\"all_data.csv\")\n",
    "df_to_label.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "df_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_label[\"label_gpt1\"] = df_to_label[\"label_gpt1\"].str.replace(\"'\", \"\")\n",
    "df_to_label[\"label_gpt2\"] = df_to_label[\"label_gpt2\"].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_same_label = df_to_label[\n",
    "    (df_to_label[\"label_gpt1\"] == df_to_label[\"label_gpt2\"])\n",
    "    & (df_to_label[\"label_gpt2\"] == df_to_label[\"label_alex\"])\n",
    "]\n",
    "print(df_filtered_same_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions for at least two columns being equal\n",
    "condition1 = df_to_label[\"label_gpt1\"] == df_to_label[\"label_gpt2\"]\n",
    "condition2 = df_to_label[\"label_gpt1\"] == df_to_label[\"label_alex\"]\n",
    "condition3 = df_to_label[\"label_gpt2\"] == df_to_label[\"label_alex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_at_least_two = df_to_label[condition1 | condition2 | condition3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_at_least_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_at_least_two[\"label_naics\"] = df_filter_at_least_two.apply(\n",
    "    lambda row: (\n",
    "        row[\"label_gpt1\"]\n",
    "        if row[\"label_gpt1\"] == row[\"label_gpt2\"]\n",
    "        or row[\"label_gpt1\"] == row[\"label_alex\"]\n",
    "        else row[\"label_gpt2\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_at_least_two=df_filter_at_least_two[[\"label\", \"description\", \"label_naics\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_at_least_two.to_csv(\"same_label_business_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_same_label = df_filtered_same_label[[\"label\", \"description\", \"label_gpt1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_at_least_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_at_least_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pd.Series(\n",
    "    df_filter_at_least_two[\"label_naics\"].values, index=df_filter_at_least_two[\"label\"]\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"naics_label\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "map_company_label = pd.Series(\n",
    "    df[\"naics_label\"].values, index=df[\"main_business_category_clean\"]\n",
    ").to_dict()\n",
    "\n",
    "with open(\"map_company_naics.json\", \"w\") as f:\n",
    "    json.dump(map_company_label, f)\n",
    "\n",
    "\n",
    "map_company_label_comercial = pd.Series(\n",
    "    df[\"main_business_category_clean\"].values, index=df[\"commercial_name_clean\"]\n",
    ").to_dict()\n",
    "\n",
    "with open(\"map_company_comercial.json\", \"w\") as f:\n",
    "    json.dump(map_company_label_comercial, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naics_keywrod = pd.read_csv(\n",
    "    \"/Users/marianluca/Projects/HackingBigNumbers/Tournament/marian/naics_summary_keywords.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naics_keywrod[\"keywords\"] = naics_keywrod[\"keywords\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naics_keywrod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_naics_keyword = pd.Series(\n",
    "    naics_keywrod[\"keywords\"].values, index=naics_keywrod[\"naics_label\"]\n",
    ").to_dict()\n",
    "\n",
    "with open(\"map_naics_keywords.json\", \"w\") as f:\n",
    "    json.dump(map_company_label_comercial, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_company_description = pd.Series(\n",
    "    df[\"commercial_name_clean\"].values, index=df[\"naics_label\"].values\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/Users/marianluca/Projects/HackingBigNumbers/Tournament/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(\"Unnamed: 0\",inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pd.Series(\n",
    "    df_filter_at_least_two[\"label_naics\"].values, index=df_filter_at_least_two[\"label\"]\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_business_to_naics = pd.Series(\n",
    "    test_data[\"answer\"].values, index=test_data[\"round_5\"]\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_number_and_text(input_string):\n",
    "    # Split the input string into parts based on space\n",
    "    parts = input_string.split(\" \", 1)  # Only split at the first space\n",
    "    number = parts[0]  # The first part will be the number\n",
    "    text = parts[1]  # The second part will be the rest of the text\n",
    "    return number, text\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "input_string = \"621 Ambulatory Health Care Services\"\n",
    "number, text = separate_number_and_text(input_string)\n",
    "print(\"Number:\", number)\n",
    "print(\"Text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def create_dataframe_from_json(directory):\n",
    "    data = []  # List to hold data from all JSON files\n",
    "\n",
    "    # Loop through every file in the specified directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):  # Check for JSON files\n",
    "            file_path = os.path.join(directory, filename)  # Full path to file\n",
    "\n",
    "            # Open and load the JSON file\n",
    "            with open(file_path, \"r\") as file:\n",
    "                content = json.load(file)\n",
    "                data.append(content)  # Append the data to the list\n",
    "\n",
    "    # Convert list of dictionaries into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_dataframe_from_json(\n",
    "    \"/Users/marianluca/Projects/HackingBigNumbers/Tournament/companies\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test_data[[\"naics_code\", \"label_naics\"]] = test_data[\"answer\"].str.split(\n",
    "    # \" \", 1)\n",
    "\n",
    "test_data[[\"naics_code\", \"naics_label\"]] = test_data[\"answer\"].str.split(\n",
    "    \" \", n=1, expand=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.rename(\n",
    "    columns={\n",
    "        \"round_1\": \"commercial_name\",\n",
    "        \"round_2\": \"business_tags\",\n",
    "        \"round_3\": \"short_description\",\n",
    "        \"round_4\": \"description\",\n",
    "        \"round_5\": \"main_business_category\",\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_bussines_to_naics = pd.Series(\n",
    "    test_data[\"naics_label\"].values, index=test_data[\"main_business_category\"]\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_bussines_to_naics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_keys = set(label_dict.keys()) & set(true_bussines_to_naics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(common_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_bussines_to_naics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for key in common_keys:\n",
    "    if true_bussines_to_naics[key] == label_dict[key]:\n",
    "        acc +=1\n",
    "    else:\n",
    "        label_dict[key] = true_bussines_to_naics[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict.update(true_bussines_to_naics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_business_to_naics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"map_business_to_naics.json\", \"w\") as f:\n",
    "    json.dump(label_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_same_label.rename(columns={\"label_gpt1\":\"label_naics\"},inplace=True)\n",
    "df_filtered_same_label.to_csv(\"same_label_business_to_naics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naics = pd.read_csv(\n",
    "    \"/Users/marianluca/Projects/HackingBigNumbers/Tournament/marian/naics_summary.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_naics_to_code = pd.Series(\n",
    "    df_naics[\"naics_code\"].values,\n",
    "    index=df_naics[\"naics_label\"],\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_directory = os.getcwd()\n",
    "\n",
    "# parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# DATA_PATH = os.path.join(parent_directory, \"data\")\n",
    "# DATA_TOURNAMENT = os.path.join(DATA_PATH, \"tournament_hints_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "DATA_PATH = os.path.join(parent_directory,\"data\")\n",
    "DATA_TOURNAMENT = os.path.join(DATA_PATH,\"tournament_hints_data.parquet\")\n",
    "\n",
    "DATA_NAICS = os.path.join(DATA_PATH, \"tournament_hints_data.parquet\")\n",
    "\n",
    "print(\"Current Directory:\", current_directory)\n",
    "print(\"Parent Directory:\", parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_TOURNAMENT)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"commercial_name\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_naics\"]= df[\"main_business_category\"].apply(lambda x: label_dict.get(x, \"Not Found\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_round = set(df.columns)\n",
    "# columns_round.remove(\"main_business_category\")\n",
    "# print(columns_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Creating an instance of LabelEncoder\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# # Fitting the encoder\n",
    "# encoder.fit(df[\"main_business_category\"].unique())\n",
    "\n",
    "# # Transforming the data\n",
    "# df[\"target\"] = encoder.transform(df[\"main_business_category\"])\n",
    "# # print(\"Encoded data:\", encoded_data)\n",
    "\n",
    "# # Inverse transforming the data\n",
    "# # decoded_data = encoder.inverse_transform(encoded_data)\n",
    "# # print(\"Decoded data:\", decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_classes(df, target_column, more_than:int = 1):\n",
    "    \"\"\"Remove rows where the target class has only one occurrence.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The dataset to be filtered.\n",
    "        target_column (str): The column name of the target variable.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Filtered dataset without rare classes.\n",
    "    \"\"\"\n",
    "    # Calculate the count of each class in the target column\n",
    "    value_counts = df[target_column].value_counts()\n",
    "\n",
    "    # Identify classes where the count is more than 1\n",
    "    classes_to_keep = value_counts[value_counts > more_than].index\n",
    "\n",
    "    # Filter the DataFrame to keep only rows with classes that have more than one occurrence\n",
    "    filtered_df = df[df[target_column].isin(classes_to_keep)]\n",
    "\n",
    "    print(\n",
    "        f\"From a total of {len(df[target_column].unique())} it remains {len(filtered_df[target_column].unique())} classes. So {len(df[target_column].unique()) - len(filtered_df[target_column].unique())} was deleted\"\n",
    "    )\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "df_filtered = remove_rare_classes(df, \"main_business_category\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"label_naics\"] = df_filtered[\"main_business_category\"].apply(\n",
    "    lambda x: label_dict.get(x, \"Not Found\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"label_naics\"]!= \"Not Found\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"naics_label\"] = df[\"main_business_category\"].apply(\n",
    "    lambda x: label_dict.get(x, \"Not Found\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(\"label_naics\", inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[df_filtered[\"label_naics\"] == \"Not Found\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered[df_filtered[\"label_naics\"] != \"Not Found\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"target\"] = df_filtered[\"label_naics\"].apply(\n",
    "    lambda x: map_naics_to_code.get(x, \"Not Found\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"test_data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered[df_filtered[\"target\"] != \"Not Found\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"target\"] = df_filtered[\"target\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = remove_rare_classes(df_filtered, \"target\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"label_naics\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_values = df_filtered[\"label_naics\"].value_counts().head(10).index\n",
    "\n",
    "# Create a new DataFrame that only contains rows with top 10 'label_naics' values\n",
    "df_top_10 = df_filtered[df_filtered[\"label_naics\"].isin(top_10_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_dataset(df_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"clean_text\"] = df_filtered[\"Tweet\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"commercial_name_clean\"] = df[\"commercial_name\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "df[\"business_tags_clean\"] = df[\"business_tags\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "df[\"short_description_clean\"] = df[\"short_description\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "df[\"description_clean\"] = df[\"description\"].apply(lambda x: clean_text(x))\n",
    "df[\"main_business_category_clean\"] = df[\"main_business_category\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.read_csv(\"cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def apply_tfidf(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Transforms text data into TF-IDF vectors.\n",
    "    Args:\n",
    "    X_train (list): Training text data.\n",
    "    X_test (list): Testing text data.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Transformed X_train and X_test.\n",
    "    \"\"\"\n",
    "    print(\"Apply TF-IDF\")\n",
    "    tfidf_transformer = TfidfVectorizer()\n",
    "    X_train_transformed = tfidf_transformer.fit_transform(X_train)\n",
    "    X_test_transformed = tfidf_transformer.transform(X_test)\n",
    "\n",
    "    return X_train_transformed, X_test_transformed\n",
    "\n",
    "\n",
    "def evaluate_models(df_train, df_test, models, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Trains models and evaluates them based on the macro F1 score.\n",
    "    Args:\n",
    "    df_train (DataFrame): Training DataFrame with 'clean_text' and 'target'.\n",
    "    df_test (DataFrame): Testing DataFrame with 'clean_text' and 'target'.\n",
    "    models (dict): Dictionary of model names and their classifier instances.\n",
    "    threshold (float): Threshold for converting probabilities to class predictions.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Best model, its name, and its F1 score.\n",
    "    \"\"\"\n",
    "    X_train, y_train = df_train[\"clean_text\"], df_train[\"target\"]\n",
    "    X_test, y_test = df_test[\"clean_text\"], df_test[\"target\"]\n",
    "\n",
    "    X_train, X_test = apply_tfidf(X_train, X_test)\n",
    "\n",
    "    best_model, best_model_name, best_f1_score = None, None, 0\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Start training {name}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        y_pred = (y_proba[:, 1] >= threshold).astype(int)\n",
    "        current_f1_score = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "        if current_f1_score > best_f1_score:\n",
    "            best_f1_score = current_f1_score\n",
    "            best_model = model\n",
    "            best_model_name = name\n",
    "\n",
    "        print_metrics(y_pred, y_test, name + \" - Text\")\n",
    "        print(f\"Test set F1-score: {current_f1_score}\")\n",
    "        print(f\"Test set Precision: {precision_score(y_test, y_pred, average='macro')}\")\n",
    "        print(f\"Test set Recall: {recall_score(y_test, y_pred, average='macro')}\")\n",
    "        print(\"\\n\\n\")\n",
    "        print(\n",
    "            \"-----------------------------------------------------------------------------------------------------------------------\"\n",
    "        )\n",
    "\n",
    "    return best_model, best_model_name, best_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_classifiers = {\n",
    "    # \"XGBClassifier\": XGBClassifier(scale_pos_weight=1, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    \"GaussianNB\":GaussianNB(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"SVC\": SVC(class_weight=\"balanced\", probability=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = \"short_description\"\n",
    "df_tmp_train, df_tmp_test = (\n",
    "    df_train[[col_name, \"target\"]],\n",
    "    df_test[[col_name, \"target\"]],\n",
    ")\n",
    "# df_tmp_train.rename(columns={col_name: \"clean_text\"}, inplace=True)\n",
    "# df_tmp_test.rename(columns={col_name:\"clean_text\"},inplace=True)\n",
    "\n",
    "df_tmp_train[\"clean_text\"] = df_tmp_train[col_name].apply(\n",
    "    lambda x: clean_text(x, to_lemmatize=True)\n",
    ")\n",
    "df_tmp_test[\"clean_text\"] = df_tmp_test[col_name].apply(\n",
    "    lambda x: clean_text(x, to_lemmatize=True)\n",
    ")\n",
    "\n",
    "evaluate_models(df_tmp_train, df_tmp_test, pipeline_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "class BERTClass(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bert_model: str = \"bert-base-uncased\",\n",
    "        num_classes: int = 2,\n",
    "        droput_rate: int = 0.3,\n",
    "    ):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model, return_dict=True)\n",
    "        self.dropout = nn.Dropout(droput_rate)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data:pd.DataFrame,tokenizer,max_length:int=128):\n",
    "\n",
    "        self.labels = data[\"target\"].to_list()\n",
    "        self.max_length = max_length\n",
    "        self.texts = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                max_length=self.max_length,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for text in df[\"text\"]\n",
    "        ]\n",
    "\n",
    "    def get_max_len(self, df):\n",
    "        return max(self.texts)\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=16, shuffle=False)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input[\"attention_mask\"].to(device)\n",
    "            input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output, train_label.long())\n",
    "            total_loss_train += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input[\"attention_mask\"].to(device)\n",
    "                input_id = val_input[\"input_ids\"].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "\n",
    "                batch_loss = criterion(output, val_label.long())\n",
    "                total_loss_val += batch_loss.item()\n",
    "\n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "\n",
    "        print(\n",
    "            f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}\"\n",
    "        )\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "\n",
    "def evaluate(model, test_data, model_name: str = \"Model name\"):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input[\"attention_mask\"].to(device)\n",
    "            input_id = test_input[\"input_ids\"].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            # predictions = output.argmax(dim=1)\n",
    "\n",
    "            prediction = F.softmax(output, dim=1).detach().cpu().numpy()\n",
    "            threshold = 0.3\n",
    "            preds = np.where(prediction[:, 1] > threshold, 1, 0)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "\n",
    "            total_acc_test += acc\n",
    "\n",
    "            y_true.extend(test_label.cpu().numpy().tolist())\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"g\")\n",
    "    plt.title(model_name)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"Test Accuracy: {total_acc_test / len(test_data): .3f}\")\n",
    "    print(f\"Test Precison: {precision: .3f}\")\n",
    "    print(f\"Test Recall: {recall: .3f}\")\n",
    "    print(f\"Test F1: {f1: .3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
